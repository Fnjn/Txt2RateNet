{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils\n",
    "import rnn_rating\n",
    "\n",
    "MAX_LENGTH = rnn_rating.MAX_LENGTH\n",
    "SOS_token = rnn_rating.SOS_token\n",
    "EOS_token = rnn_rating.EOS_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 3668 sentence lines\n",
      "Trimmed to 1427 sentence lines\n",
      "Counting words...\n",
      "Counted words:\n",
      "2590\n",
      "('dope shop', 5.0)\n",
      "200 1227\n"
     ]
    }
   ],
   "source": [
    "text, lines = rnn_rating.prepareData('attn_input.txt', 'attn_target.txt')\n",
    "print(random.choice(lines))\n",
    "\n",
    "test_lines = lines[-200:]\n",
    "lines = lines[:-200]\n",
    "print(len(test_lines), len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, \\\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    loss += criterion(decoder_output, target_tensor)\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [rnn_rating.tensorsFromLine(text, random.choice(lines))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (utils.timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = rnn_rating.tensorFromSentence(text, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        \n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        return decoder_output.data, decoder_attention.data\n",
    "    \n",
    "\n",
    "def evaluateRandomly(encoder, decoder, lines, n=10):\n",
    "    for i in range(n):\n",
    "        line = random.choice(lines)\n",
    "        print('>', line[0])\n",
    "        print('=', line[1])\n",
    "        output, attention = evaluate(encoder, decoder, line[0])\n",
    "        print('<', output)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(encoder, decoder, input_tensor, target_tensor, criterion, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        input_length = input_tensor.size(0)\n",
    "    \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        loss = criterion(decoder_output, target_tensor)\n",
    "        return loss.item()\n",
    "    \n",
    "def IterTest(encoder, decoder, test_lines):\n",
    "    criterion = nn.MSELoss()\n",
    "    test_pairs = [rnn_rating.tensorsFromLine(text, line) for line in test_lines] \n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(test_pairs)):\n",
    "        test_pair = test_pairs[i]\n",
    "        input_tensor = test_pair[0]\n",
    "        target_tensor = test_pair[1]\n",
    "\n",
    "        loss += Test(encoder, decoder, input_tensor, target_tensor, criterion)\n",
    "        \n",
    "    mse = loss / len(test_lines)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "# encoder = rnn_rating.EncoderRNN(text.n_words, hidden_size).to(device)\n",
    "# attn_decoder = rnn_rating.AttnDecoderRNN(hidden_size, text.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "# trainIters(encoder, attn_decoder, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-80f084b89653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": [
    "showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_model.pth')\n",
    "torch.save(attn_decoder.state_dict(), 'decoder_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = rnn_rating.EncoderRNN(text.n_words, hidden_size).to(device)\n",
    "encoder.load_state_dict(torch.load('encoder_model.pth'))\n",
    "\n",
    "attn_decoder = rnn_rating.AttnDecoderRNN(hidden_size, text.n_words, dropout_p=0.1).to(device)\n",
    "attn_decoder.load_state_dict(torch.load('decoder_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> omg so awesome ! ! ! only negative is your own temptation to just go spend crazy cuz they got everything u want need\n",
      "= 5.0\n",
      "< tensor([[4.2075]], device='cuda:0')\n",
      "\n",
      "> muy buenos tattos . .algun dia me tatuara kat\n",
      "= 5.0\n",
      "< tensor([[4.5920]], device='cuda:0')\n",
      "\n",
      "> i highly recommend this place !\n",
      "= 5.0\n",
      "< tensor([[4.7039]], device='cuda:0')\n",
      "\n",
      "> central location tasty sandwiches a variety of fruity beverages . friendly service too .\n",
      "= 4.0\n",
      "< tensor([[4.8277]], device='cuda:0')\n",
      "\n",
      "> good amount of food for a decent price . the house prime rib was enough to get me stuffed !\n",
      "= 4.0\n",
      "< tensor([[2.4632]], device='cuda:0')\n",
      "\n",
      "> nice food ok service not very special .\n",
      "= 3.0\n",
      "< tensor([[2.9204]], device='cuda:0')\n",
      "\n",
      "> best ny style pizza joint this side of jersey ! eggplant and mozzarella ftw .\n",
      "= 5.0\n",
      "< tensor([[4.3483]], device='cuda:0')\n",
      "\n",
      "> fun place to play paintball !\n",
      "= 5.0\n",
      "< tensor([[4.6981]], device='cuda:0')\n",
      "\n",
      "> central location tasty sandwiches a variety of fruity beverages . friendly service too .\n",
      "= 4.0\n",
      "< tensor([[4.8277]], device='cuda:0')\n",
      "\n",
      "> best staff in town . quick reliable service .\n",
      "= 5.0\n",
      "< tensor([[4.8311]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, attn_decoder, test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2401601590967584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IterTest(encoder, attn_decoder, test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa825360400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder, attn_decoder, random.choice(lines)[0])\n",
    "plt.matshow(attentions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "#     ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "#                        ['<EOS>'], rotation=90)\n",
    "#     ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, attn_decoder, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', output_words.item())\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = by dollar general market\n",
      "output = 3.0067038536071777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanjin/CSE/UCSD-CSE-258-Assgn2/ENV/lib/python3.5/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(random.choice(lines)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
